

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>DL models for Edge Inference &mdash; Processor SDK Linux for Edge AI Documentation</title>
  

  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
  
    <link rel="stylesheet" href="_static/theme_overrides.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="Processor SDK Linux for Edge AI Documentation" href="index.html"/>
        <link rel="next" title="Demo Configuration file" href="configuration_file.html"/>
        <link rel="prev" title="Running Simple demos" href="running_simple_demos.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">
  <header id="tiHeader">
    <div class="top">
      <ul>
        <li id="top_logo">
          <a href="http://www.ti.com">
            <img src="_static/img/ti_logo.png"/>
          </a>
        </li>
      </ul>
    </div>
    <div class="nav"></div>
  </header>
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Processor SDK Linux for Edge AI
          

          
          </a>

          
            
            
              <div class="version">
                08.02.01
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="sdk_overview.html">Processor SDK Linux for Edge AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="running_simple_demos.html">Running Simple demos</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">DL models for Edge Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#model-downloader-tool">Model Downloader Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="#import-custom-models">Import Custom Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#dnn-directory-structure">DNN directory structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="#param-file-format">Param file format</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dnn-compilation-for-sdk-basic-instructions">DNN compilation for SDK – Basic Instructions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dnn-compilation-for-sdk-advanced-instructions">DNN compilation for SDK – Advanced Instructions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="configuration_file.html">Demo Configuration file</a></li>
<li class="toctree-l1"><a class="reference internal" href="running_advance_demos.html">Running Advance demos</a></li>
<li class="toctree-l1"><a class="reference internal" href="docker_environment.html">Docker Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_flows.html">Data Flows</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_visualizer.html">Performance Visualization Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="connectivity.html">Connectivity and Peripherals</a></li>
<li class="toctree-l1"><a class="reference internal" href="sdk_components.html">SDK Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="roadmap.html">SDK Roadmap</a></li>
<li class="toctree-l1"><a class="reference internal" href="release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="datasheet.html">Datasheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_report.html">Test Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="development_flow.html">SDK Development flow</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQs</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">Processor SDK Linux for Edge AI</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>DL models for Edge Inference</li>
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="dl-models-for-edge-inference">
<span id="pub-edgeai-inference-models"></span><h1>DL models for Edge Inference<a class="headerlink" href="#dl-models-for-edge-inference" title="Permalink to this headline">¶</a></h1>
<div class="section" id="model-downloader-tool">
<h2>Model Downloader Tool<a class="headerlink" href="#model-downloader-tool" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://github.com/TexasInstruments/edgeai-modelzoo">TI Model Zoo</a>
is a large collection of deep learning models validated to work on TI processors
for edge AI. It hosts several pre-compiled model artifacts for TI hardware.</p>
<p>Use the <strong>Model Downloader Tool</strong> to download more models on target as shown,</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>root@j7-evm:/opt/edge_ai_apps# ./download_models.sh
</pre></div>
</div>
<p>The script will launch an interactive menu showing the list of available,
pre-imported models for download. The downloaded models will be placed
under <code class="docutils literal notranslate"><span class="pre">/opt/model_zoo/</span></code> directory</p>
<div class="figure align-center" id="id1">
<img alt="_images/model_downloader.png" src="_images/model_downloader.png" />
<p class="caption"><span class="caption-number">Fig. 11 </span><span class="caption-text">Model downloader tool menu option to download models</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p>The script can also be used in a non-interactive way as shown below:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>root@j7-evm:/opt/edge_ai_apps# ./download_models.sh --help
</pre></div>
</div>
</div>
<div class="section" id="import-custom-models">
<span id="pub-edgeai-import-custom-models"></span><h2>Import Custom Models<a class="headerlink" href="#import-custom-models" title="Permalink to this headline">¶</a></h2>
<p>The Processor SDK Linux for Edge AI also supports importing pre-trained custom
models to run inference on target.</p>
<p>The SDK makes use of pre-compiled DNN (Deep Neural Network) models and performs
inference using various OSRT (open source runtime) such as TFLite runtime,
ONNX runtime and Neo AI-DLR. In order to infer a DNN, SDK expects the DNN and
associated artifacts in the below directory structure.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>TFL-OD-2010-ssd-mobV2-coco-mlperf-300x300
│
├── param.yaml
│
├── artifacts
│   ├── 264_tidl_io_1.bin
│   ├── 264_tidl_net.bin
│   ├── 264_tidl_net.bin.layer_info.txt
│   ├── 264_tidl_net.bin_netLog.txt
│   ├── 264_tidl_net.bin.svg
│   ├── allowedNode.txt
│   └── runtimes_visualization.svg
│
└── model
    └── ssd_mobilenet_v2_300_float.tflite
</pre></div>
</div>
<div class="section" id="dnn-directory-structure">
<h3>DNN directory structure<a class="headerlink" href="#dnn-directory-structure" title="Permalink to this headline">¶</a></h3>
<p>Each DNN must have the following 3 components:</p>
<ol class="arabic simple">
<li><p><strong>model</strong>: This directory contains the DNN being targeted to infer</p></li>
<li><p><strong>artifacts</strong>: This directory contains the artifacts generated after the
compilation of DNN for SDK, and described in <a class="reference internal" href="#pub-edgeai-compile-artifacts"><span class="std std-ref">DNN compilation for SDK – Basic Instructions</span></a></p></li>
<li><p><strong>param.yaml</strong>: A configuration file in yaml format to provide basic
information about DNN, and associated pre and post processing parameters.
More details can be find <a class="reference internal" href="#pub-edgeai-params"><span class="std std-ref">Param file format</span></a></p></li>
</ol>
</div>
<div class="section" id="param-file-format">
<span id="pub-edgeai-params"></span><h3>Param file format<a class="headerlink" href="#param-file-format" title="Permalink to this headline">¶</a></h3>
<p>Each DNN has it’s own pre-process, inference and post-process
parameters to get the correct output. This information is typically available in
the training software that was used to train the model. In order to convey this
information to the SDK in a standardized fashion, we have defined a set of
parameters that describe these operations. These parameters are in the
param.yaml file.</p>
<p>Please see sample yaml files for various tasks such as image classification,
semantic segmentation and object detection in
<a class="reference external" href="https://github.com/TexasInstruments/edgeai-benchmark/tree/master/examples/configs/yaml">edgeai-benchmark examples</a>.
Descriptions of various parameters are also in the yaml files. If users want to
bring their own model to the SDK, then they need to prepare this information
offline and get to the SDK. In next section we explain how to prepare this
information</p>
</div>
<div class="section" id="dnn-compilation-for-sdk-basic-instructions">
<span id="pub-edgeai-compile-artifacts"></span><h3>DNN compilation for SDK – Basic Instructions<a class="headerlink" href="#dnn-compilation-for-sdk-basic-instructions" title="Permalink to this headline">¶</a></h3>
<p>The Processor SDK Linux for Edge AI supports three different runtimes to infer
a DNN, and user can choose a run time depending on the format of DNN.
We recommend users to use different run times and compare the performance and
select the one which provides best performance. User can find the steps to
generate the artifacts directory at
<a class="reference external" href="https://github.com/TexasInstruments/edgeai-tidl-tools/blob/master/examples/osrt_python/README.md#model-compilation-on-pc">Edge AI TIDL Tools</a></p>
</div>
<div class="section" id="dnn-compilation-for-sdk-advanced-instructions">
<h3>DNN compilation for SDK – Advanced Instructions<a class="headerlink" href="#dnn-compilation-for-sdk-advanced-instructions" title="Permalink to this headline">¶</a></h3>
<p>For beginners who are trying to compile models for the SDK, we recommend the
basic instructions given in the previous section. However, DNNs have lot of
variety and some models may need a different kind of preprocessing or postprocessing
operations. In order to help customers deal with different kinds of models, we
have prepared a model zoo in the repository
<a class="reference external" href="https://github.com/TexasInstruments/edgeai-modelzoo">edgeai-modelzoo</a></p>
<p>For the DNNs which are part of TI’s model zoo, one can find the compilation
settings and pre-compiled model artifacts in
<a class="reference external" href="https://github.com/TexasInstruments/edgeai-benchmark">edgeai-benchmark</a>
repository. Instructions are also given to compile custom models.
When using <a class="reference external" href="https://github.com/TexasInstruments/edgeai-benchmark">edgeai-benchmark</a> for model compilation, the yaml file is automatically
generated and artifacts are packaged in the way SDK understands. Please
follow the instructions in the repository to get started.</p>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="configuration_file.html" class="btn btn-neutral float-right" title="Demo Configuration file" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="running_simple_demos.html" class="btn btn-neutral" title="Running Simple demos" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
      <a href="http://www.ti.com/corp/docs/legal/copyright.shtml">&copy; Copyright 2021-2022</a>, Texas Instruments Incorporated. All rights reserved. <br>
      <a href="http://www.ti.com/corp/docs/legal/trademark/trademrk.htm">Trademarks</a> | <a href="http://www.ti.com/corp/docs/legal/privacy.shtml">Privacy policy</a> | <a href="http://www.ti.com/corp/docs/legal/termsofuse.shtml">Terms of use</a> | <a href="http://www.ti.com/lsds/ti/legal/termsofsale.page">Terms of sale</a>

    </p>
  </div> 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

    <script src="http://www.ti.com/assets/js/headerfooter/analytics.js" type="text/javascript" charset="utf-8"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
        });

      var menuHeight = window.innerHeight;

      var contentOffset = $(".wy-nav-content-wrap").offset();
      var contentHeight = $(".wy-nav-content-wrap").height();
      var contentBottom = contentOffset.top + contentHeight;

      function setNavbarTop() {
          var scrollTop = $(window).scrollTop();
          var maxTop = scrollTop + menuHeight;

          // If past the header
          if (scrollTop > contentOffset.top && maxTop < contentBottom) {
            stickyTop = scrollTop - contentOffset.top;
          } else if (maxTop > contentBottom) {
            stickyTop = scrollTop - contentOffset.top - (maxTop - contentBottom);
          } else {
            stickyTop = 0;
          }

          $(".wy-nav-side").css("top", stickyTop);
      }

      $(document).ready(function() {
        setNavbarTop();
        $(window).scroll(function () {
          setNavbarTop();
        });
      });
  </script>
   

</body>
</html>